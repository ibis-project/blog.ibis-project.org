{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Optimizing for speed and memory use"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Python bindings for `libhs2client` are careful about performance and memory in a few key ways:\n",
      "\n",
      "- Converting row batches directly into pandas-compatible NumPy arrays\n",
      "- Care with categorical data: string data is deduplicated while it's being converted for pandas. In the future, it would be straightforward to add an option to return all string data as `pandas.Categorical` arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## hs2client demo and simple benchmark\n",
      "\n",
      "The initial API is oriented at modeling the HiveServer2 protocol closely. Connecting to a cluster yields a `Service` instance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hs2client\n",
      "\n",
      "service = hs2client.connect('localhost', 21050, 'wesm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To execute queries, you open a session then use its `execute` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "session = service.open_session()\n",
      "\n",
      "op = session.execute(\"select 1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Queries are asynchronous by default."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "op.is_finished"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "op.get_state()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'finished'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Result sets can be fetch currently to `pandas.DataFrame` objects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = op.fetchall_pandas()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   1\n",
        "0  1"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compared with comparable database clients, we've optimized the fetch path to have excellent performance (IO speeds) and memory use. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "N, K = 1000000, 10\n",
      "\n",
      "df = pd.DataFrame(np.random.randn(N, K),\n",
      "                  columns=['data{0}'.format(i) for i in range(K)])\n",
      "\n",
      "import ibis\n",
      "con = ibis.impala.connect('localhost', \n",
      "                          hdfs_client=ibis.hdfs_connect(port=5070))\n",
      "con.drop_database('hs2_test', force=True)\n",
      "con.create_database('hs2_test')\n",
      "con.create_table('test_data', df, database='hs2_test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "op = session.execute_sync('select * from hs2_test.test_data')\n",
      "%time df = op.fetchall_pandas()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 200 ms, sys: 64 ms, total: 264 ms\n",
        "Wall time: 682 ms\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "speed = df.memory_usage().sum() / 0.682 / 2**20\n",
      "print('Speed: {0:.2f} MB/s'.format(speed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Speed: 111.87 MB/s\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This benchmark is being run on `localhost`, but it shows we can move over 110 MB/s through the Thrift protocol **and** convert to a fully-formed pandas DataFrame."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## hs2client compared with impyla\n",
      "\n",
      "In Ibis and other Python projects, we have been using [impyla](http://github.com/cloudera/impyla) to execute queries and access result sets. impyla either uses Apache Thrift's official Python implementation (on Python 2) or [thriftpy](https://github.com/eleme/thriftpy) (on Python 3) for interacting with the Impala or Hive Thrift service. Because of this, the main difference is the performance in fetching large result sets.\n",
      "\n",
      "Here, I will perform an equivalent fetch using impyla via ibis:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Connect to Impala via impyla (on Python 2)\n",
      "con = ibis.impala.connect('localhost', port=21050)\n",
      "\n",
      "expr = con.sql('select * from hs2_test.test_data')\n",
      "\n",
      "%time df = expr.execute(limit=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.15 s, sys: 52 ms, total: 1.2 s\n",
        "Wall time: 1.66 s\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "speed = df.memory_usage().sum() / 1.66 / 2**20\n",
      "print('Speed: {0:.2f} MB/s'.format(speed))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Speed: 45.96 MB/s\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this particular use case with an all-numeric table (which is ideal for deserialization performance), the speed difference is only 2x or a bit more."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## hs2client roadmap\n",
      "\n",
      "The [code is hosted on GitHub](http://github.com/cloudera/hs2client).\n",
      "\n",
      "The C++ library does not yet implement some important features that are needed to be a drop-in replacement for impyla or other Hive or Impala drivers:\n",
      "\n",
      "* SSL transport (with certificate verification)\n",
      "* SASL Thrift transport for secure (i.e. Kerberos) clusters, or insecure clusters using SASL\n",
      "\n",
      "On the Python side, we must implement a DB API 2.0 compatibility layer, since currently data can only be fetched to pandas, not Python tuples as with most Python database drivers.\n",
      "\n",
      "We of course welcome contributions from the community to build out some of these features. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}